{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('~/train.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning:\n",
      "\n",
      "Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('~/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3563475, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 774497 entries, 0 to 774496\n",
      "Data columns (total 5 columns):\n",
      "id           774497 non-null object\n",
      "qid1         774497 non-null object\n",
      "qid2         774492 non-null object\n",
      "question1    774485 non-null object\n",
      "question2    774478 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 29.5+ MB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =training_df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df =training_df.drop(columns=['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_check = pd.concat([training_df[['question1','question2']], test_df[['question1','question2']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_dict={}\n",
    "    \n",
    "for i in stopwords.words('english'):\n",
    "    sw_dict[i]=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem import PorterStemmer\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "lemi_words=[]\n",
    "stem_words=[]\n",
    "lmtzr = nltk.WordNetLemmatizer().lemmatize\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "def do_lemitise(word):\n",
    "    old_word=word\n",
    "    word = lmtzr(word)\n",
    "    if word != old_word:\n",
    "        lemi_words.append((old_word, word))\n",
    "        \n",
    "    return word\n",
    "    \n",
    "def do_stem(word):\n",
    "    old_word=word\n",
    "    word = stem(word)\n",
    "    if word != old_word:\n",
    "        stem_words.append((old_word, word))\n",
    "    return word\n",
    "        \n",
    "\n",
    "def do_process_word(word):\n",
    "    word = do_stem(word)\n",
    "    word = do_lemitise(word)\n",
    "    return word\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def corpus_filteration(dfList):\n",
    "    \n",
    "    actual_list =[]\n",
    "    \n",
    "\n",
    "    \n",
    "    item_num=0\n",
    "\n",
    "    for k, v in dfList.iteritems():\n",
    "        questions_corpus = re.sub('[^a-zA-Z]',' ', str(v)).lower().split()\n",
    "        questions_corpus = [do_process_word(word) for word in questions_corpus if word not in sw_dict.keys()]\n",
    "        \n",
    "        actual_list.append(questions_corpus)\n",
    "        item_num = item_num + 1\n",
    "        if (item_num%1000000 == 0):\n",
    "            print (\"Done so far {} \".format(item_num) )\n",
    "    \n",
    "    return actual_list           \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error1_cf = corpus_filteration(training_df['question1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error2_cf = corpus_filteration(training_df['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done so far 1000000 \n",
      "Done so far 2000000 \n",
      "Done so far 3000000 \n",
      "Done so far 1000000 \n",
      "Done so far 2000000 \n",
      "Done so far 3000000 \n"
     ]
    }
   ],
   "source": [
    "test_question_list= corpus_filteration(temp_check['question1']) + corpus_filteration(temp_check['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_question_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file=open(\"test_question_list.txt\",mode=\"a\")\n",
    "\n",
    "\n",
    "for i in test_question_list:\n",
    "    new_file.writelines(i)\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'step'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(test_question_list, min_count=1,size=50)\n",
    "\n",
    "\n",
    "\n",
    "words = list(model.wv.vocab)\n",
    "\n",
    "model.save('model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_model = KeyedVectors.load('model.bin')\n",
    "word2vec_model.init_sims(replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.word2vec.Word2Vec'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyemd import emd\n",
    "def distance_calculation(d1,d2):\n",
    "        i=j=0\n",
    "        distance_list=[]\n",
    "        len_train_01 =len(d1)\n",
    "        len_train_02 =len(d2)\n",
    "        item_num=0\n",
    "        \n",
    "        \n",
    "        while (i<len_train_01 and j<len_train_02):\n",
    "            distance_questions = word2vec_model.wv.wmdistance(d1[i], d2[j])\n",
    "            #f.write(str(distance_questions))\n",
    "            distance_list.append(distance_questions)\n",
    "            i=i+1\n",
    "            j=j+1\n",
    "            item_num = item_num + 1\n",
    "            if (item_num%100000 == 0):\n",
    "                print (\"Done so far {} \".format(item_num) )\n",
    "        \n",
    "        training_df['is_duplicate_01']=distance_list\n",
    "        return training_df['is_duplicate_01']\n",
    "        #return distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done so far 100000 \n",
      "Done so far 200000 \n",
      "Done so far 300000 \n",
      "Done so far 400000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0.182588\n",
       "1         0.794831\n",
       "2         0.522713\n",
       "3         1.230278\n",
       "4         0.934650\n",
       "5         0.602225\n",
       "6         1.343568\n",
       "7         0.457476\n",
       "8         0.000000\n",
       "9         0.643127\n",
       "10        1.200547\n",
       "11        0.563762\n",
       "12        0.000000\n",
       "13        0.305871\n",
       "14        0.085295\n",
       "15        0.769805\n",
       "16        0.000000\n",
       "17        0.408174\n",
       "18        0.575044\n",
       "19        0.120852\n",
       "20        0.663469\n",
       "21        0.300835\n",
       "22        0.000000\n",
       "23        1.317550\n",
       "24        0.769116\n",
       "25        0.199825\n",
       "26        0.318798\n",
       "27        0.769089\n",
       "28        0.250733\n",
       "29        0.653618\n",
       "            ...   \n",
       "404260    0.574573\n",
       "404261    0.297097\n",
       "404262    0.285560\n",
       "404263    0.558133\n",
       "404264    0.819386\n",
       "404265    0.381791\n",
       "404266    0.938127\n",
       "404267    0.427773\n",
       "404268    0.924855\n",
       "404269    0.490077\n",
       "404270    0.000000\n",
       "404271    0.811712\n",
       "404272    0.709233\n",
       "404273    0.508930\n",
       "404274    0.493883\n",
       "404275    0.694403\n",
       "404276    0.147626\n",
       "404277    1.004356\n",
       "404278    0.506764\n",
       "404279    0.846021\n",
       "404280    0.205289\n",
       "404281    0.370509\n",
       "404282    0.276981\n",
       "404283    0.648177\n",
       "404284    0.276918\n",
       "404285    0.188833\n",
       "404286    0.257623\n",
       "404287    0.650308\n",
       "404288    1.314624\n",
       "404289    0.000000\n",
       "Name: is_duplicate_01, Length: 404290, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_calculation(training_error1_cf,training_error2_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning:\n",
      "\n",
      "set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done so far 100000 \n",
      "Done so far 200000 \n",
      "Done so far 300000 \n",
      "Done so far 400000 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "item_num =0\n",
    "for i, row in training_df['is_duplicate_01'].iteritems():\n",
    "    if row == 0.000000:\n",
    "        training_df.set_value(i,'is_duplicate_01',int(1))\n",
    "    elif (row >= 0.28 and row <= 0.72):\n",
    "        training_df.set_value(i,'is_duplicate_01',int(1))\n",
    "    else:\n",
    "        training_df.set_value(i,'is_duplicate_01',int(0))\n",
    "    item_num = item_num + 1\n",
    "    if (item_num%100000 == 0):\n",
    "        print (\"Done so far {} \".format(item_num) )\n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_df['is_duplicate_01'] = training_df['is_duplicate_01'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score =67.30 when dimension=100\n",
    "#chaging to 300 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_length_corpus(training_error1_cf):\n",
    "    \n",
    "    min_length=0\n",
    "    max_length=len(training_error1_cf[0])\n",
    "    \n",
    "    for i in range(0,len(training_error1_cf)):\n",
    "        if len(training_error1_cf[i]) <=min_length :\n",
    "            min_length= len(training_error1_cf[i])\n",
    "        \n",
    "    \n",
    "    for i in range(1,len(training_error1_cf)):\n",
    "        if len(training_error1_cf[i]) > max_length:\n",
    "            max_length= len(training_error1_cf[i])\n",
    "        \n",
    "    \n",
    "    avg_length= (min_length + max_length)//2\n",
    "    \n",
    "    \n",
    "    return min_length,max_length,avg_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_question1_training_set= avg_length_corpus(training_error1_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_question2_training_set= avg_length_corpus(training_error2_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_trainging_questions_array(training_error1_cf):\n",
    "    questions_length_array =[]\n",
    "    for i in training_error1_cf:\n",
    "        questions_length_array.append(len(i))\n",
    "        \n",
    "    return questions_length_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question_1_length =len_trainging_questions_array(training_error1_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2_length =len_trainging_questions_array(training_error2_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/ubuntu/temp-plot.html'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "trace = go.Box(\n",
    "    y= question_2_length,\n",
    "    name='Mean & SD',\n",
    "    marker=dict(\n",
    "        color='rgb(10, 140, 208)',\n",
    "    ),\n",
    "    boxmean='sd'\n",
    ")\n",
    "data = [trace]\n",
    "#py.iplot(data)\n",
    "plotly.offline.plot(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_entries(input_array):\n",
    "    \n",
    "    final_result=[]\n",
    "    new_array=[]\n",
    "    unseen=set()\n",
    "    count=0\n",
    "    for i in input_array:\n",
    "        for j in i:\n",
    "                 if j not in unseen:\n",
    "                    unseen.add(j)\n",
    "                    final_result.append(word2vec_model[j])\n",
    "                    #final_result.append(j)\n",
    "        if len(final_result) >5:\n",
    "            final_result=final_result[0:5]\n",
    "        else:\n",
    "            array_length=len(final_result)\n",
    "            while array_length <5:\n",
    "                final_result.append(np.zeros(50))\n",
    "                array_length=array_length +1\n",
    "                    \n",
    "        new_array.append(final_result)\n",
    "        final_result=[]\n",
    "            \n",
    "    \n",
    "    return new_array\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_training_set_question1 =duplicate_entries(training_error1_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector_training_set_question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_training_set_question2 =duplicate_entries(training_error2_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(vector_training_set_question1)\n",
    "b = np.array(vector_training_set_question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=np.column_stack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.10, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reshape(363861, in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(40429, in_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.regularizers import L1L2\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning:\n",
      "\n",
      "Update your `LSTM` call to the Keras 2 API: `LSTM(50, input_shape=(1, 500), return_sequences=True, recurrent_dropout=0.2)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dense(2, activation='relu'))\n",
    "model.add(LSTM(50, dropout_U =0.2,input_shape=(1, 500),return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax',input_dim=500) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327474 samples, validate on 36387 samples\n",
      "Epoch 1/50\n",
      "327474/327474 [==============================] - 54s 165us/step - loss: 0.6552 - acc: 0.6314 - val_loss: 0.6530 - val_acc: 0.6284\n",
      "Epoch 2/50\n",
      "327474/327474 [==============================] - 53s 162us/step - loss: 0.6499 - acc: 0.6309 - val_loss: 0.6490 - val_acc: 0.6273\n",
      "Epoch 3/50\n",
      "327474/327474 [==============================] - 54s 165us/step - loss: 0.6476 - acc: 0.6294 - val_loss: 0.6472 - val_acc: 0.6258\n",
      "Epoch 4/50\n",
      "327474/327474 [==============================] - 53s 162us/step - loss: 0.6469 - acc: 0.6289 - val_loss: 0.6468 - val_acc: 0.6257\n",
      "Epoch 5/50\n",
      "327474/327474 [==============================] - 53s 163us/step - loss: 0.6467 - acc: 0.6287 - val_loss: 0.6470 - val_acc: 0.6260\n",
      "Epoch 6/50\n",
      "327474/327474 [==============================] - 53s 162us/step - loss: 0.6465 - acc: 0.6287 - val_loss: 0.6462 - val_acc: 0.6259\n",
      "Epoch 7/50\n",
      "327474/327474 [==============================] - 53s 162us/step - loss: 0.6463 - acc: 0.6287 - val_loss: 0.6461 - val_acc: 0.6259\n",
      "Epoch 8/50\n",
      "327474/327474 [==============================] - 53s 162us/step - loss: 0.6462 - acc: 0.6287 - val_loss: 0.6460 - val_acc: 0.6259\n",
      "Epoch 9/50\n",
      "327474/327474 [==============================] - 53s 162us/step - loss: 0.6461 - acc: 0.6287 - val_loss: 0.6458 - val_acc: 0.6259\n",
      "Epoch 10/50\n",
      "305568/327474 [==========================>...] - ETA: 3s - loss: 0.6457 - acc: 0.6291"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_split=0.10,epochs=50,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test,verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print('First prediction:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples1, nx1, ny1 = X_test.shape\n",
    "X_test = X_test.reshape((nsamples1,nx1*ny1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=2)  \n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= RandomForestRegressor(n_estimators=1000)\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X,y)\n",
    "#Predict Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted= model.predict(Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
